\documentclass[conference]{IEEEtran}

\newcommand{\thetitle}{Non-Parametric Discrete Mixture Model Recovery with Nonnegative Matrix Factorization}

\input{packages}
\input{definitions}

\title{\vspace{-0.25em}\thetitle}
\author{
{\large{Stefan~Karpinski, John~R.~Gilbert, Elizabeth~M.~Belding}} \vspace{0.25em}\\
Department of Computer Science \\
University of California, Santa Barbara \vspace{0.35em}\\
\textit{\{sgk,gilbert,ebelding\}@cs.ucsb.edu}
}

\graphicspath{{graphics/}}

\begin{document}
\maketitle

Mixture modeling expresses probability densities as convex combinations of constituent probability distributions:
\begin{align}
  q(x) = \sum_{i=1}^n w_i p_i(x).
\end{align}
The constituent density functions, $p_i$, may be taken from a finite set of known distributions, or more commonly a class of parametric distributions.
In such settings, there are well-established algorithms, such as expectation minimization (\caps{EM}), that can optimally recover the weights, $w_i$, for an observed sample of values from $q$.

In certain settings, however, mixture modeling is desirable, but the constituent distributions are neither known in advance, nor can they be assumed to be parametric.
In this work, we demonstrate how nonnegative matrix factorization (\caps{NMF}) can be effectively used to simultaneously recover weights and non-parametric constituent distributions, starting only from a large collection of variably-sized samples from unknown mixtures.
% Our work addresses mixture models over discrete event spaces, but can be applied readily to continuous spaces, since continuous quantities can be discretized, and our techniques then applied to the resulting large discrete spaces. Since our approach makes no parametric assumptions, the results are no less valid.

\end{document}
